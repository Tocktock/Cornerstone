# Cornerstone environment example
# Copy to .env.local or export variables as needed before running the app/tests.

# Embedding configuration
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
OPENAI_API_KEY=
# To use Ollama embeddings instead, set EMBEDDING_MODEL=ollama:qwen3-embedding (or another pulled model)

# Chat backend selection and defaults
CHAT_BACKEND=openai
OPENAI_CHAT_MODEL=gpt-5-mini

# Retrieval reranker configuration (optional)
# RERANKER_STRATEGY=embedding
# RERANKER_MODEL=cross-encoder/ms-marco-MiniLM-L-6-v2
# RERANKER_MAX_CANDIDATES=8

# Qdrant vector store
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=
QDRANT_COLLECTION=embeddings
# Uncomment to enable on-disk payload/vector storage and custom HNSW tuning
# QDRANT_ON_DISK_PAYLOAD=1
# QDRANT_ON_DISK_VECTORS=1
# QDRANT_HNSW_M=32
# QDRANT_HNSW_EF_CONSTRUCT=256
# QDRANT_HNSW_FULL_SCAN_THRESHOLD=20000

# Local Ollama backend (optional)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b
OLLAMA_TIMEOUT=60
# Increase if using heavy Ollama embedding models to parallelise HTTP requests
# OLLAMA_EMBEDDING_CONCURRENCY=4

# Glossary controls
GLOSSARY_PATH=glossary/glossary.yaml
GLOSSARY_TOP_K=3

# Knowledge management
DATA_DIR=data
DEFAULT_PROJECT_NAME=Default Project
RETRIEVAL_TOP_K=3
# CHAT_TEMPERATURE=0.2
# CHAT_MAX_TOKENS=600
# KEYWORD_LLM_MAX_CANDIDATES=25000
# KEYWORD_LLM_MAX_TOKENS=750000
# KEYWORD_LLM_MAX_CHUNKS=10000
# KEYWORD_RUN_MAX_CONCURRENCY=1
# KEYWORD_RUN_MAX_QUEUE=8
# KEYWORD_RUN_CACHE_TTL=86400
# KEYWORD_RUN_AUTO_REFRESH=0
# KEYWORD_RUN_SYNC_MODE=1

# Observability metrics
# OBSERVABILITY_METRICS_ENABLED=1
# OBSERVABILITY_NAMESPACE=cornerstone
